package log_streaming_access_bridge

import (
	"context"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/nsofnetworks/terraform-provider-pfptmeta/internal/client"
	"net/http"
)

const (
	description = `Proofpoint log streaming allows you to send log data from the Proofpoint NaaS tenant to a third-party service in real time. Then, the log data can be stored and analyzed using a Security Information and Event Management (SIEM) solution. Proofpoint supports the following log streaming standards:

- Splunk-compatible HTTP Event Collector (HEC), enabling you to send data over HTTP (or HTTPS) directly to Splunk Enterprise or Splunk Cloud from Proofpoint NaaS. Splunk HEC is token-based, eliminating the need to hard-code your Splunk credentials into Proofpoint-provided applications.
- IBM QRadar-compatible HTTP for collecting flow and event data from all of the log sources that are supported in your on-premises or cloud deployment.
- Amazon S3 service for direct streaming of the customerâ€™s tenant logs to an AWS S3 bucket.
- Syslog Common Event Format (CEF), an open-source log management standard. CEF allows third parties to create their own device schemas that are compatible with industry-standard methods for normalizing security events.
- Proofpoint CASB - Proofpoint log streamer can be configured to send traffic or web security logs to Proofpoint CASB for shadow IT processing. 
This integration enables organizations to govern user access to both IT-authorized and unauthorized apps (also known as shadow IT)

You can use previously configured notification channels for receiving alerts on events from log streaming service. 
When the log streamer status changes to one of the non-running states (error, suspended, stopped) a notification event is triggered.`
	notificationChannelDesc = "Notification Channel IDs to which an alert will be sent if the log streaming service becomes unavailable or the endpoint is unreachable."
	exportLogsDesc          = "Enum: `api` `traffic` `security` `metaproxy` `webfilter`."

	proofpointCASBConfig = "Configuration for log streaming to Proofpoint CASB for shadow IT processing.."
	casbRegionDesc       = "Tenant region in Proofpoint CASB system. ENUM: `EU`, `US`."
	casbTenantIDDesc     = "Your organization PCASB tenant ID in the tenant_ID format. Valid tenant ID format is *tenant<32 hex characters>*"

	qRadarConfDesc = "Configuration for log streaming to IBM QRadar platform."
	qRadarURLDesc  = "QRadar server URL."
	qRadarCertDesc = "Base64 root CA certificate."

	s3ConfDesc     = "Configuration for log streaming to an Amazon S3 bucket."
	s3BucketDesc   = "Name of your AWS S3 bucket. Must have proper writing permissions and access rights for the Proofpoint logging."
	s3CompressDesc = "Whether to compress log objects using gzip"
	s3Prefix       = "Shared name prefix for destination object in your AWS S3 bucket."

	splunkDesc = "Configuration for log streaming to Self-Hosted / cloud Splunk." +
		" see [here](https://help.metanetworks.com/knowledgebase/log_streaming_for_splunk_self_hosted/#configuring-splunk-http-event-collector) for instructions on how to enable HTTP Event Collector on Self-Hosted Instance," +
		" and [here](https://help.metanetworks.com/knowledgebase/log_streaming_for_splunk_cloud/#configuring-splunk-http-event-collector) for instructions on how to enable HTTP Event Collector on Cloud Instance"
	splunkCerDesc                = "Base 64 server for the root CA certificate."
	splunkPubliclyAccessibleDesc = "Whether the Splunk instance URL endpoint is publicly available."
	splunkTokenDesc              = "Token code generated by Splunk HEC."
	splunkURLDesc                = "Splunk server HTTP event collector URI. This field accepts an FQDN value only."

	syslogDesc      = "Configuration for log streaming in Syslog Common Event Format (CEF)."
	syslogHostDesc  = "SIEM destination FQDN."
	syslogPortDesc  = "TCP port for log data input."
	syslogProtoDesc = "ENUM: `tcp`, `udp`."
)

const (
	proofpointCASB = "proofpoint_casb"
	qradarHTTP     = "qradar_http"
	s3             = "s3"
	splunkHTTP     = "splunk_http"
	sysLog         = "syslog"
)

var ExcludedKeys = []string{"id", "ldap_provisioning_config", "siem_config", "type"}

func accessBridgeToResource(d *schema.ResourceData, ab *client.AccessBridge) (diags diag.Diagnostics) {
	d.SetId(ab.ID)
	err := client.MapResponseToResource(ab, d, ExcludedKeys)
	if err != nil {
		return diag.FromErr(err)
	}
	origBody := client.NewAccessBridge(d)
	siemConf := make([]map[string]interface{}, 1)
	siemConf[0] = make(map[string]interface{})
	switch ab.SiemConfig.Type {
	case proofpointCASB:
		if ab.SiemConfig.ProofpointCasbConfig != nil {
			conf := []map[string]interface{}{
				{
					"region":    ab.SiemConfig.ProofpointCasbConfig.Region,
					"tenant_id": ab.SiemConfig.ProofpointCasbConfig.TenantId,
				},
			}
			siemConf[0]["proofpoint_casb_config"] = conf
		}
	case qradarHTTP:
		if ab.SiemConfig.QradarHttpConfig != nil {
			conf := []map[string]interface{}{
				{
					"certificate": origBody.SiemConfig.QradarHttpConfig.Certificate,
					"url":         ab.SiemConfig.QradarHttpConfig.Url,
				},
			}
			siemConf[0]["qradar_http_config"] = conf
		}
	case s3:
		if ab.SiemConfig.S3Config != nil {
			conf := []map[string]interface{}{
				{
					"bucket":   ab.SiemConfig.S3Config.Bucket,
					"compress": ab.SiemConfig.S3Config.Compress,
					"prefix":   ab.SiemConfig.S3Config.Prefix,
				},
			}
			siemConf[0]["s3_config"] = conf
		}
	case splunkHTTP:
		if ab.SiemConfig.SplunkHttpConfig != nil {
			conf := []map[string]interface{}{
				{
					"certificate":         origBody.SiemConfig.SplunkHttpConfig.Certificate,
					"publicly_accessible": ab.SiemConfig.SplunkHttpConfig.PubliclyAccessible,
					"token":               origBody.SiemConfig.SplunkHttpConfig.Token,
					"url":                 ab.SiemConfig.SplunkHttpConfig.Url,
				},
			}
			siemConf[0]["splunk_http_config"] = conf
		}
	case sysLog:
		if ab.SiemConfig.SyslogConfig != nil {
			conf := []map[string]interface{}{
				{
					"host":  ab.SiemConfig.SyslogConfig.Host,
					"port":  ab.SiemConfig.SyslogConfig.Port,
					"proto": ab.SiemConfig.SyslogConfig.Proto,
				},
			}
			siemConf[0]["syslog_config"] = conf
		}
	}
	exportLogs := make([]string, len(ab.SiemConfig.ExportLogs))
	for i, val := range ab.SiemConfig.ExportLogs {
		exportLogs[i] = val
	}
	siemConf[0]["export_logs"] = exportLogs
	err = d.Set("siem_config", siemConf)
	if err != nil {
		return diag.FromErr(err)
	}
	return
}

func abRead(ctx context.Context, d *schema.ResourceData, meta interface{}) (diags diag.Diagnostics) {
	c := meta.(*client.Client)

	id := d.Get("id").(string)
	ab, err := client.GetAccessBridge(ctx, c, id)
	if err != nil {
		errResponse, ok := err.(*client.ErrorResponse)
		if ok && errResponse.Status == http.StatusNotFound {
			d.SetId("")
			return
		} else {
			return diag.FromErr(err)
		}
	}
	return accessBridgeToResource(d, ab)
}
func abCreate(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)

	body := client.NewAccessBridge(d)
	ab, err := client.CreateAccessBridge(ctx, c, body)
	if err != nil {
		return diag.FromErr(err)
	}
	return accessBridgeToResource(d, ab)
}

func abUpdate(ctx context.Context, d *schema.ResourceData, meta interface{}) diag.Diagnostics {
	c := meta.(*client.Client)

	id := d.Id()
	body := client.NewAccessBridge(d)
	ab, err := client.UpdateAccessBridge(ctx, c, id, body)
	if err != nil {
		return diag.FromErr(err)
	}
	return accessBridgeToResource(d, ab)
}

func abDelete(ctx context.Context, d *schema.ResourceData, meta interface{}) (diags diag.Diagnostics) {
	c := meta.(*client.Client)

	id := d.Id()
	_, err := client.DeleteAccessBridge(ctx, c, id)
	if err != nil {
		errResponse, ok := err.(*client.ErrorResponse)
		if ok && errResponse.Status == http.StatusNotFound {
			d.SetId("")
		} else {
			return diag.FromErr(err)
		}
	}
	d.SetId("")
	return
}
